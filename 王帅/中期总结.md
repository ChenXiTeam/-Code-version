

@[TOC](目录)

</font>

<hr style=" border:solid; width:100px; height:1px;" color=#000000 size=1">

# 前言

项目已经推进到了第八周，做一个中期的总结。



# 第一周
主要内容：
是确定小组成员；
考虑项目内容；
联系指导老师；
确定分工。

也是出于大一大二的学习经历考虑，想到做一个代码的检错与查重桌面应用，方便批改提交的作业；
没有设计为web应用主要是由于服务器的运行维护。

我负责的部分是代码的提取，主要包括实验报告和图片。






# 第二周
根据指导老师的提示和网络上的一些资料，考虑项目的技术手段；
最初的想法是用第三方工具tika实现对内容的提取，用python写前端，用java实现后端，通过导入jar包的方式实现前后端相连，于是我尝试了：
1.使用python语言，pycharm利用pyqt使用qt designer写前端界面；
2.使用java语言，IDEA导入并调用tika；
3.将java文件封装成jar包导入。
期间出现了很多问题，运行的效率也非常低。



# 第三周
上一周的经历启发了我：用java写是为了提高处理效率，但是效果非常不好，不如直接使用python的第三方库，这样反而可以简化程序，释放容量，避免很多没有必要的调试和导入。
对于实验报告的提取，我使用了python的docx库；
处理的速度非常快，足以处理实际应用场景中实验报告的数量；
方法也比较简单，只需要分别提取docx文档的段落与表格，就能提取到所有文字内容；
考虑到后期队友的进一步处理，我暂时把读取到的内容以原文件名保存在一个txt文件中；
利用qt信号和槽的技术，实现对输入输出路径的选择；
这样就完成了对实验报告文字内容的提取。


# 第四周
提取图片内容的技术：ocr。
找到了ocr开源项目：Tesseract；
需要配置环境；
同时试用了Tess4J；
在命令行提取简单的图片内容，效果还不错；
我想到了上周的思路，仍然用python的第三方库完成提取；
第三方库：pytesseract，也就是对tesseract做的一层Python API封装；
这样就可以使用python语言方便的调用；
尝试识别代码，发现识别的准确度极低，无法满足需求；
于是寻找提高识别准确度的方法：样本训练、二值化处理；
二值化处理需要用到cv2库，由于版本的问题，用起来问题很多；
对于不同的图片要找到合适的阈值，才能提高清晰度；
进行灰度值处理也是同样的效果；
使用样本训练的手段十分麻烦，下载jTessBoxEditor；
核心思想是对一个图片的识别结果进行挨个字符的处理；
作为tif处理，创建字体特征文件、批处理文件，从而形成语言文件；
以新的语言文件作为语言库继续识别；
这样下来，少量代码就要更正许久，效率极低，准确度也不高；
不得已，决定使用成熟的百度ocr接口；
可以免费创建一个ocr项目，调用其接口，准确度基本没有问题。






# 第五周
考虑把现有的功能封装在一起；
主类：pick_main
方法类：pick_method
ui类：pick_ui
主类连接前后端，ui类为界面，方法类包括所有的提取方法和处理手段；
这样就可以通过界面实现相应操作了。
还要做到正文代码分离，用正则表达式实现；
将标注的代码部分提出来，每个部分作为一个文件储存；
对于文件的命名，也需要相应的方法实现：
1.通过ui界面选择输入输出路径；
2.通过切片处理，生成相应的输出文件名和路径；
3.将这些路径生成文件（txt），写入提取结果；
4.命名规则是原文件命-后缀+内容属性和自增序号。
图片和docx文档的提取优先级一样，需要手动选择。




# 第六周
提取的部分已经暂时足够使用，考虑拓展一下业务：网络查重
在网络上查找了相关资料，没有什么太有价值的思路；
现在的设想就是利用爬虫爬取相应关键字的内容，再同本地文件对比。
六个py文件分别完成:
1.条件输入
2.建立搜索引擎连接
3.获取本地文件内容
4.分析爬取结果
5.整合封装各个功能
6.其他的条件扩展
如果后期使用这个思路，要加入数据库储存爬取结果。




# 第七周
根据队友的需求，为提取部分补充功能；
通过docx文件为压缩文件的性质，找到并提出其中的图片；
对于多种语言的处理，目前仅处理4种：c，cpp，java，python
需要去掉代码中的注释，用正则表达式实现；
类似方法去掉代码中的空行；
将代码输出为：
1.一个大字符串，方便后续的查重；
2.一个源代码文件，方便后续的代码检查。
大字符串需要去掉注释和空行；
源代码文件需要识别提取到的文本是什么代码，实现方法：
正则表达式处理内嵌代码时就分类，处理结果的文件后缀改为相应类型即可。
但是带来一个问题：图片识别不能用相似的原理；
考虑直接识别代码的txt文件，根据特征判断种类；
目前使用fuzzywuzzy库进行相似度的比对；
1.提取出的代码转化为txt后，取得它前边的n个字符作为判断依据；
2.设计几组各种语言可能的开头与之进行比对；
3.相似度最高的结果就可以认为是该种类的代码。
这样做的原因：标注的代码都是完整代码而不是片段，开头具有一定标志性。


# 第八周

与队友整合所有功能。
我起作用的就是那些提取方法，根据要求又做了一些微调。




<hr style=" border:solid; width:100px; height:1px;" color=#000000 size=1">

# 总结
项目已经能有一个运行的demo，但是各个功能都还不完善。继续努力！
